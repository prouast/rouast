<!DOCTYPE html>
<html lang="en">
<head>
  <!-- standard meta -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
  <meta name="author" content="Philipp Rouast">
  <meta name="description" content="I am a PhD candidate at the University of Newcastle, Australia. My research focuses on human-centered applications of deep learning and computer vision.">
  <!-- site properties -->
  <title>Philipp Rouast</title>
  <!-- inject:css -->
  <link rel="stylesheet" type="text/css" href="css/styles.css">
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/fomantic-ui@2.7.5/dist/semantic.min.css">
  <!-- Global site tag - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-92777237-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-92777237-2');
  </script>
  <!-- endinject -->
</head>
<body>
  <!-- Fixed menu -->
  <div class="ui fixed inverted large menu">
    <div class="ui container">
      <a href="#top" class="item" id="topMenu">
        <i class="home icon"></i>
      </a>
      <a href="#projects" class="item" id="projectsMenu">Projects</a>
      <a href="#publications" class="item" id="publicationsMenu">Publications</a>
      <a href="#timeline" class="item" id="timelineMenu">Timeline</a>
    </div>
  </div>
  <!-- Intro -->
  <div class="ui inverted vertical center aligned segment">
    <div class="ui text container">
      <center><img class="ui small circular image" src="/img/prouast.jpg" alt="Philipp Rouast"></center>
      <h1 class="ui inverted header">
        Philipp Rouast
      </h1>
      <a class="ui white link" href="mailto:philipp@rouast.com?Subject=Oh%20hi%20philipp">
        <i class="envelope icon"></i>
        Email
      </a>
      <h3>I am a PhD candidate at the University of Newcastle, Australia. My research focuses on human-centered applications of deep learning and computer vision.</h3>
    </div>
  </div>
  <!-- Projects -->
  <div id="projects" class="segment">
    <div class="ui center aligned container">
      <h2 class="ui header">Projects</h2>
      <h5 class="ui horizontal divider header">
        <i class="wrench icon"></i>
        Some projects I've worked on.
      </h5>
    </div>
    <div class="ui hidden divider"></div>
    <div class="ui container">
      <div class="ui three stackable cards">
        <div class="ui card">
          <div class="image">
            <img src="/img/intake_detection.jpg" alt="Automatic detection of individual intake gestures based on 360-degree video and deep learning.">
          </div>
          <div class="content">
            <span class="header">Intake gesture detection</span>
            <div class="meta">
              <i class="calendar icon"></i>
              <span class="date">2018 - 2019</span>
              <i class="building icon"></i>
              <span class="partner">UON</span>
              <i class="file code icon"></i>
              <span class="code">Python</span>
              <span class="code">TensorFlow</span>
            </div>
            <div class="description">
              Automatic detection of individual intake gestures based on 360-degree video and deep learning.
            </div>
          </div>
          <div class="extra content">
            <a href="https://github.com/prouast/deep-intake-detection">
              <button class="ui button">
                <i class="github icon"></i>
                GitHub
              </button>
            </a>
            <a>
              <button id="modal1" class="ui green button">
                <i class="play icon"></i>
                Try
              </button>
            </a>
          </div>
        </div>
        <div class="ui card">
          <div class="image">
            <img src="/img/rppg.jpg" alt="Contactless heart rate measurement based on face video, implemented for desktop and mobile">
          </div>
          <div class="content">
            <span class="header">rPPG</span>
            <div class="meta">
              <i class="calendar icon"></i>
              <span class="date">2015 - 2016</span>
              <i class="building icon"></i>
              <span class="partner">UON/KIT</span>
              <i class="file code icon"></i>
              <span class="code">C++</span>
              <span class="code">OpenCV</span>
            </div>
            <div class="description">
              Contactless heart rate measurement based on face video, implemented for desktop and mobile.
            </div>
          </div>
          <div class="extra content">
            <a href="https://github.com/prouast/heartbeat">
              <button class="ui button">
                <i class="github icon"></i>
                GitHub
              </button>
            </a>
            <a href="https://www.youtube.com/watch?v=D_KYv7pXAvQ">
              <button class="ui youtube button">
                <i class="youtube icon"></i>
                YouTube
              </button>
            </a>
          </div>
        </div>
        <div class="ui card">
          <div class="image">
            <img src="/img/equirectangular-remap.jpg" alt="Generate maps for conversions from spherical to equirectangular in ffmpeg.">
          </div>
          <div class="content">
            <span class="header">Equirectangular remap</span>
            <div class="meta">
              <i class="calendar icon"></i>
              <span class="date">2017</span>
              <i class="building icon"></i>
              <span class="partner">UON</span>
              <i class="file code icon"></i>
              <span class="code">C</span>
              <span class="code">ffmpeg</span>
            </div>
            <div class="description">
              Generate maps for conversions from spherical to equirectangular in ffmpeg.
            </div>
          </div>
          <div class="extra content">
            <a href="https://github.com/prouast/equirectangular-remap">
              <button class="ui button">
                <i class="github icon"></i>
                GitHub
              </button>
            </a>
          </div>
        </div>
      </div>
    </div>
    <div class="ui container" id="hidableProjects">
      <div class="ui three stackable cards">
        <div class="ui card">
          <div class="image">
            <img src="/img/cryptocurrency-analysis.jpg" alt="Correlations between returns in the cryptocurrency market.">
          </div>
          <div class="content">
            <span class="header">Cryptocurrency analysis</span>
            <div class="meta">
              <i class="calendar icon"></i>
              <span class="date">2017</span>
              <i class="file code icon"></i>
              <span class="date">R</span>
            </div>
            <div class="description">
              Analysis and visualisation of the cryptocurrency market.
            </div>
          </div>
          <div class="extra content">
            <a href="https://github.com/prouast/cryptocurrency-analysis">
              <button class="ui button">
                <i class="github icon"></i>
                GitHub
              </button>
            </a>
          </div>
        </div>
        <div class="ui card">
          <div class="image">
            <img src="/img/brownie.jpg">
          </div>
          <div class="content">
            <span class="header">Brownie</span>
            <div class="meta">
              <i class="calendar icon"></i>
              <span class="date">2016</span>
              <i class="building icon"></i>
              <span class="partner">KIT</span>
              <i class="file code icon"></i>
              <span class="date">Java</span>
            </div>
            <div class="description">
              A NeuroIS tool for conducting economic experiments.
            </div>
          </div>
          <div class="extra content">
            <a href="https://im.iism.kit.edu/1093_1100.php">
              <button class="ui button">
                <i class="home icon"></i>
                Project Page
              </button>
            </a>
          </div>
        </div>
        <div class="ui card">
          <div class="image">
            <img src="/img/planspiel.png">
          </div>
          <div class="content">
            <span class="header">Planspiel Fl√§chenhandel</span>
            <div class="meta">
              <i class="calendar icon"></i>
              <span class="date">2014</span>
              <i class="building icon"></i>
              <span class="partner">KIT</span>
              <i class="file code icon"></i>
              <span class="date">Java</span>
              <span class="date">JavaScript</span>
              <span class="date">Grails</span>
            </div>
            <div class="description">
              Web-based simulation game for emissions certificate trading.
            </div>
          </div>
          <div class="extra content">
            <a href="http://www.flaechenhandel.de/index.html">
              <button class="ui button">
                <i class="home icon"></i>
                Project Page
              </button>
            </a>
          </div>
        </div>
      </div>
    </div>
    <div class="ui hidden divider"></div>
    <div class="ui center aligned container">
      <button id="projectsButton" class="ui basic primary button">
        Show more
      </button>
    </div>
  </div>
  <!-- Publications -->
  <div id="publications" class="segment">
    <div class="ui center aligned container">
      <h2 class="ui header">Publications</h2>
      <h5 class="ui horizontal divider header">
        <i class="pencil alternate icon"></i>
        Current and forthcoming publications.
      </h5>
    </div>
    <div class="ui hidden divider"></div>
    <div class="ui container">
      <div class="ui items">
        <div class="item">
          <div class="image">
            <img src="/img/affect_recognition.png" alt="Deep Learning for Human Affect Recognition: Insights and New Developments">
          </div>
          <div class="content">
            <a href="https://ieeexplore.ieee.org/abstract/document/8598999/" class="header">Deep Learning for Human Affect Recognition: Insights and New Developments</a>
            <div class="authors">
              <span><u>Philipp V. Rouast</u>, Marc T. P. Adam, Raymond Chiong</span>
            </div>
            <div class="meta">
              <span>IEEE Transactions on Affective Computing</span>
            </div>
            <div class="description">
              <p>
                Automatic human affect recognition is a key step towards more natural human-computer interaction. Recent trends include recognition in the wild using a fusion of audiovisual and physiological sensors, a challenging setting for conventional machine learning algorithms. Since 2010, novel deep learning algorithms have been applied increasingly in this field.
                <span id="dotsTAC">...</span>
                <span id="moreTAC">
                  In this paper, we review the literature on human affect recognition between 2010 and 2017, with a special focus on approaches using deep neural networks. By classifying a total of 950 studies according to their usage of shallow or deep architectures, we are able to show a trend towards deep learning. Reviewing a subset of 233 studies that employ deep neural networks, we comprehensively quantify their applications in this field. We find that deep learning is used for learning of (i) spatial feature representations, (ii) temporal feature representations, and (iii) joint feature representations for multimodal sensor data. Exemplary state-of-the-art architectures illustrate the recent progress. Our findings show the role deep architectures will play in human affect recognition, and can serve as a reference point for researchers working on related applications.
                </span>
                <a id="buttonTAC">Read more</a>
              </p>
            </div>
            <div class="extra">
              <a href="pdf/rouast2019deep.pdf" class="ui basic label">
                <i class="file pdf icon"></i>
                PDF
              </a>
              <span class="links"><a href="https://arxiv.org/abs/1901.02884">arXiv</a></span>
              <span class="links"><a href="https://scholar.google.com.au/scholar?cluster=17643367748425293417">Google Scholar</a></span>
              <span class="links"><a href="https://ieeexplore.ieee.org/abstract/document/8598999/">IEEE Xplore</a></span>
              <span class="links"><a href="https://www.researchgate.net/publication/329980556_Deep_Learning_for_Human_Affect_Recognition_Insights_and_New_Developments">ResearchGate</a></span>
            </div>
          </div>
        </div>
        <div class="item">
          <div class="image">
            <img src="/img/ecis.png" alt="Using deep learning and 360 video to detect eating behavior for user assistance systems">
          </div>
          <div class="content">
            <a href="https://aisel.aisnet.org/ecis2018_rp/101/" class="header">Using deep learning and 360 video to detect eating behavior for user assistance systems</a>
            <div class="authors">
              <span><u>Philipp V. Rouast</u>, Marc T. P. Adam, Tracy Burrows, Raymond Chiong, Megan Rollo</span>
            </div>
            <div class="meta">
              <span>European Conference on Information Systems (ECIS 2018)</span>
            </div>
            <div class="description">
              <p>
                The rising prevalence of non-communicable diseases calls for more sophisticated approaches to support individuals in engaging in healthy lifestyle behaviors, particularly in terms of their dietary intake. Building on recent advances in information technology, user assistance systems hold the potential of combining active and passive data collection methods to
                <span id="dotsECIS">...</span>
                <span id="moreECIS">
                  monitor dietary intake and, subsequently, to support individuals in making better decisions about their diet. In this paper, we review the state-of-the-art in active and passive dietary monitoring along with the issues being faced. Building on this groundwork, we propose a research framework for user assistance systems that combine active and passive methods with three distinct levels of assistance. Finally, we outline a proof-of-concept study using video obtained from a 360-degree camera to automatically detect eating behavior from video data as a source of passive dietary monitoring for decision support.
                </span>
                <a id="buttonECIS">Read more</a>
              </p>
            </div>
            <div class="extra">
              <a href="pdf/rouast2018using.pdf" class="ui basic label">
                <i class="file pdf icon"></i>
                PDF
              </a>
              <span class="links"><a href="https://aisel.aisnet.org/ecis2018_rp/101/">AIS eLibrary</a></span>
              <span class="links"><a href="https://scholar.google.com.au/scholar?cluster=15963458291069625288">Google Scholar</a></span>
              <span class="links"><a href="https://www.researchgate.net/publication/328475515_Using_Deep_Learning_and_360_Video_to_Detect_Eating_Behavior_for_User_Assistance_Systems">ResearchGate</a></span>
            </div>
          </div>
        </div>
        <div class="item">
          <div class="image">
            <img src="/img/fcs.png" alt="Remote heart rate measurement using low-cost RGB face video: a technical literature review">
          </div>
          <div class="content">
            <a href="https://link.springer.com/article/10.1007/s11704-016-6243-6" class="header">Remote heart rate measurement using low-cost RGB face video: a technical literature review</a>
            <div class="authors">
              <span><u>Philipp V. Rouast</u>, Marc T. P. Adam, Raymond Chiong, David Cornforth, Eva Lux</span>
            </div>
            <div class="meta">
              <span>Frontiers of Computer Science 12 (5), 858-872</span>
            </div>
            <div class="description">
              <p>
                Remote photoplethysmography (rPPG) allows remote measurement of the heart rate using low-cost RGB imaging equipment. In this study, we review the development of the field of rPPG since its emergence in 2008. We also classify existing rPPG approaches and derive a framework that provides an overview of modular steps.
                <span id="dotsFCS">...</span>
                <span id="moreFCS">
                  Based on this framework, practitioners can use our classification to design algorithms for an rPPG approach that suits their specific needs. Researchers can use the reviewed and classified algorithms as a starting point to improve particular features of an rPPG algorithm.
                </span>
                <a id="buttonFCS">Read more</a>
              </p>
            </div>
            <div class="extra">
              <a href="pdf/rouast2016remote_a.pdf" class="ui basic label">
                <i class="file pdf icon"></i>
                PDF
              </a>
              <span class="links"><a href="https://scholar.google.com.au/scholar?cluster=7619880296834415536">Google Scholar</a></span>
              <span class="links"><a href="https://www.researchgate.net/publication/306285292_Remote_heart_rate_measurement_using_low-cost_RGB_face_video_A_technical_literature_review">ResearchGate</a></span>
              <span class="links"><a href="https://link.springer.com/article/10.1007/s11704-016-6243-6">SpringerLink</a></span>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="ui container" id="hidablePublications">
      <div class="ui items">
        <div class="item">
          <div class="image">
            <img src="/img/AITIC.png" alt="Remote photoplethysmography: Evaluation of contactless heart rate measurement in an information systems setting">
          </div>
          <div class="content">
            <a class="header">Remote photoplethysmography: Evaluation of contactless heart rate measurement in an information systems setting</a>
            <div class="authors">
              <span><u>Philipp V. Rouast</u>, Marc T. P. Adam, Verena Dorner, Eva Lux</span>
            </div>
            <div class="meta">
              <span>Applied Informatics and Technology Innovation Conference (AITIC 2016)</span>
            </div>
            <div class="description">
              <p>
                As a source of valuable information about a person‚Äôs affective state, heart rate data has the potential to improve both understanding and experience of human-computer interaction. Conventional methods for measuring heart rate use skin contact methods, where a measuring device must be worn by the user. In an Information
                <span id="dotsAITIC">...</span>
                <span id="moreAITIC">
                  Systems setting, a contactless approach without interference in the user‚Äôs natural environment could prove to be advantageous. We develop an application that fulfils these conditions. The algorithm is based on remote photoplethysmography, taking advantage of the slight skin color variation that occurs periodically with the user‚Äôs pulse. When evaluating this application in an Information Systems setting with various arousal levels and naturally moving subjects, we achieve an average root mean square error of 7.32 bpm for the best performing configuration. We find that a higher frame rate yields better results than a larger size moving measurement window. Regarding algorithm specifics, we find that a more detailed algorithm using the three RGB signals slightly outperforms a simple algorithm using only the green signal.
                </span>
                <a id="buttonAITIC">Read more</a>
              </p>
            </div>
            <div class="extra">
              <a href="pdf/rouast2016remote_b.pdf" class="ui basic label">
                <i class="file pdf icon"></i>
                PDF
              </a>
              <span class="links"><a href="https://scholar.google.com.au/scholar?oi=bibs&hl=en&cluster=16146844465437811687">Google Scholar</a></span>
              <span class="links"><a href="https://www.researchgate.net/publication/329228553_Remote_Photoplethysmography_Evaluation_of_Contactless_Heart_Rate_Measurement_in_an_Information_Systems_Setting">ResearchGate</a></span>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="ui hidden divider"></div>
    <div class="ui center aligned container">
      <button id="publicationsButton" class="ui basic primary button">
        Show more
      </button>
    </div>
  </div>
  <!-- Timeline -->
  <div id="timeline" class="segment">
    <div class="ui center aligned container">
      <h2 class="ui header">Timeline</h2>
      <h5 class="ui horizontal divider header">
        <i class="graduation cap icon"></i>
        Timeline of my positions and education.
      </h5>
    </div>
    <div class="ui hidden divider"></div>
    <div class="ui container">
      <div class="ui stackable divided two column grid">
        <div class="column">
          <center><h3>Positions</h3></center>
          <div class="ui large feed">
            <div class="event">
              <div class="label">
                <img src="/img/uon.png">
              </div>
              <div class="content">
                <div class="summary">
                  <a href="https://www.newcastle.edu.au/">The University of Newcastle</a>: Teaching Assistant (<a href="https://www.newcastle.edu.au/about-uon/governance-and-leadership/faculties-and-schools/faculty-of-engineering-and-built-environment/school-of-electrical-engineering-and-computing">SEEC</a>)
                  <div class="date">
                    2015; 2017 - now
                  </div>
                </div>
                <div class="extra text">
                  <ul class="ui list">
                    <li>EBUS3050: The Digital Economy</li>
                    <li>INFT2150: Business Analysis</li>
                    <li>INFT6201: Big Data</li>
                    <li>COMP1010: Computing Fundamentals</li>
                  </ul>
                </div>
              </div>
            </div>
            <div class="event">
              <div class="label">
                <img src="/img/kit.png">
              </div>
              <div class="content">
                <div class="summary">
                  <a href="https://www.kit.edu/english/index.php">Karlsruhe Institute of Technology</a>: Student Research Assistant (<a href="https://im.iism.kit.edu/english/index.php">IISM</a>)
                  <div class="date">
                    2012 - 2015; 2016
                  </div>
                </div>
                <div class="extra text">
                  <ul class="ui list">
                    <li>Development of a web-based prediction market (Groovy/Grails)</li>
                    <li>Development of experiment platform <a href="https://im.iism.kit.edu/1093_1100.php">Brownie</a> (Java)</li>
                  </ul>
                </div>
              </div>
            </div>
            <div class="event">
              <div class="label">
                <img src="/img/msg.jpg">
              </div>
              <div class="content">
                <div class="summary">
                  <a href="https://www.msg-gillardon.de/">msgGillardon AG</a>: Internship
                  <div class="date">
                    2013 - 2014
                  </div>
                </div>
                <div class="extra text">
                  <ul class="ui list">
                    <li>Evaluation of assumptions in the Credit Risk Model <i>CreditMetrics</i></li>
                    <li>Implementing improvements for Loss Given Default estimation for retail credits</li>
                  </ul>
                </div>
              </div>
            </div>
            <div class="event">
              <div class="label">
                <img src="/img/kit.png">
              </div>
              <div class="content">
                <div class="summary">
                  <a href="https://www.kit.edu/english/index.php">Karlsruhe Institute of Technology</a>: Teaching Assistant (<a href="aifb.kit.edu/web/Hauptseite/en">AIFB</a>)
                  <div class="date">
                    2011 - 2012
                  </div>
                </div>
                <div class="extra text">
                  <ul class="ui list">
                    <li>Programming I: Java</li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="column">
          <center><h3>Education</h3></center>
          <div class="ui large feed">
            <div class="event">
              <div class="label">
                <img src="/img/uon.png">
              </div>
              <div class="content">
                <div class="summary">
                  <a href="https://www.newcastle.edu.au/">The University of Newcastle</a>: PhD
                  <div class="date">
                    2017 - now
                  </div>
                </div>
                <div class="ui small label">
                  <i class="yellow star icon"></i> Int. Postgraduate Research Scholarship
                </div>
                <div class="ui small label">
                  <i class="yellow trophy icon"></i> <a href="https://www.acphis.org.au">ACPHIS</a> Student Project Award 2017
                </div>
                <div class="ui small label">
                  <i class="yellow trophy icon"></i> 2017 UON FEBE Postgraduate Research Prize
                </div>
                <div class="extra text">
                  <b>Thesis</b>: Using deep learning to detect food intake behaviour from video.
                </div>
              </div>
            </div>
            <div class="event">
              <div class="label">
                <img src="/img/kit.png">
              </div>
              <div class="content">
                <div class="summary">
                  <a href="https://www.kit.edu/english/index.php">Karlsruhe Institute of Technology</a>: MSc
                  <div class="date">
                    2014 - 2016
                  </div>
                </div>
                <div class="ui small label">
                  <i class="yellow trophy icon"></i> Future Award 2016: Category Health
                </div>
                <div class="ui small label">
                  <i class="yellow star icon"></i> DAAD FIT Worldwide Scholarship
                </div>
                <div class="ui small label">
                  <i class="yellow star icon"></i> BW Study Abroad Scholarship
                </div>
                <div class="extra text">
                  <b>Thesis</b>: Contactless Heart Rate Measurement Using Facial Video: A Real-Time Approach and Evaluation in Information Systems.
                </div>
              </div>
            </div>
            <div class="event">
              <div class="label">
                <img src="/img/kit.png">
              </div>
              <div class="content">
                <div class="summary">
                  <a href="https://www.kit.edu/english/index.php">Karlsruhe Institute of Technology</a>: BSc
                  <div class="date">
                    2010 - 2013
                  </div>
                </div>
                <div class="extra text">
                  <b>Thesis</b>: Partisan Trading Activity: Investigation of a Political Stock Market.
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <!-- Footer -->
  <div class="ui inverted vertical footer segment">
    <div class="ui container">
      <div class="ui six column center aligned grid">
        <div class="one wide column">
          <a class="ui white link" href="https://github.com/prouast">
            <i class="github large icon"></i>
          </a>
        </div>
        <div class="one wide column">
          <a class="ui white link" href="https://scholar.google.com.au/citations?user=Ny9vtjcAAAAJ&hl=en">
            <i class="google large icon"></i>
          </a>
        </div>
        <div class="one wide column">
          <a class="ui white link" href="https://www.instagram.com/prouast/">
            <i class="instagram large icon"></i>
          </a>
        </div>
        <div class="one wide column">
          <a class="ui white link" href="https://www.linkedin.com/in/prouast">
            <i class="linkedin large icon"></i>
          </a>
        </div>
        <div class="one wide column">
          <a class="ui white link" href="https://stackoverflow.com/users/3595278/prouast">
            <i class="stack overflow large icon"></i>
          </a>
        </div>
        <div class="one wide column">
          <a class="ui white link" href="https://www.twitter.com/prouast">
            <i class="twitter large icon"></i>
          </a>
        </div>
      </div>
    </div>
  </div>
  <div class="ui small modal">
    <div class="ui active inverted dimmer" id="modal1Dimmer">
      <div class="ui text loader">Waiting for camera</div>
    </div>
    <div class="header">
      Intake gesture detection (alpha version <i class="flask icon"></i>)
    </div>
    <div class="content">
      <p>In this demo, the small version of our 2D CNN for intake gesture recognition runs directly in your browser. It takes one raw video frame at a time as input to predict the <font color="red">frame-level probability of an intake event</font>. These probabilities are displayed in the graph on the right.</p>
      <p>For best results, place device on a table and sit such that the upper body fills most of the video.</p>
      <div class="ui stackable two column grid">
        <div class="six wide column">
          <div class="webcam-box-outer">
            <div class="webcam-box-inner">
              <video autoplay playsinline muted id="webcam" width="192" height="192"></video>
            </div>
          </div>
        </div>
        <div class="ten wide column">
          <div class="ui text loader" id="graph1Loader">Waiting for model</div>
          <canvas id="chart"></canvas>
        </div>
      </div>
    </div>
  </div>
  <!-- JS -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/fomantic-ui@2.7.5/dist/semantic.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/1.2.2/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js@2.8.0"></script>
  <script type="module" src="js/index.js"></script>
  <script type="module" src="js/intake/buffer.js"></script>
  <script type="module" src="js/intake/demo.js"></script>
  <script type="module" src="js/intake/ui.js"></script>
  <!-- /JS -->
</body>
</html>
